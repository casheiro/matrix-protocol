/**
 * RealTimeUsageMonitor - Sistema de monitoramento de uso em tempo real
 * 
 * Monitora consumption de prompts, performance dos agents, estado das filas
 * e otimiza√ß√µes do Claude Code Pro plan em tempo real com dashboards e alertas
 */

import { rateLimitHandler } from '../utils/OptimizedRateLimitHandler'
import { ContextOptimizer } from '../utils/ContextOptimizer'
import { PriorityQueueManager } from '../core/PriorityQueueManager'
import { AgentBatchOperations } from '../core/AgentBatchOperations'

interface UsageMetrics {
  prompts: PromptUsageMetrics
  performance: PerformanceMetrics
  queue: QueueMetrics
  agents: AgentMetrics
  system: SystemMetrics
  efficiency: EfficiencyMetrics
}

interface PromptUsageMetrics {
  currentCycle: {
    used: number
    remaining: number
    total: number
    resetTime: Date | null
    efficiency: number
  }
  historical: {
    dailyAverage: number
    weeklyTrend: number[]
    peakUsage: number
    optimalUsage: number
  }
  predictions: {
    cyclePrediction: number
    dailyPrediction: number
    weeklyPrediction: number
    bottleneckRisk: number
  }
}

interface PerformanceMetrics {
  responseTime: {
    average: number
    p95: number
    p99: number
    trend: number[]
  }
  throughput: {
    tasksPerHour: number
    successRate: number
    errorRate: number
    retryRate: number
  }
  context: {
    reuseRate: number
    compressionRatio: number
    cacheHitRate: number
    optimizationScore: number
  }
}

interface QueueMetrics {
  sizes: Map<string, number>
  waitTimes: {
    average: number
    byPriority: Map<string, number>
    trend: number[]
  }
  throughput: {
    itemsPerMinute: number
    completionRate: number
    backlogGrowth: number
  }
  health: {
    starvationRisk: number
    deadlineRisk: number
    capacityUtilization: number
  }
}

interface AgentMetrics {
  individual: Map<string, AgentPerformance>
  collaboration: {
    handoffEfficiency: number
    communicationQuality: number
    dependencyResolution: number
  }
  workload: {
    distribution: Map<string, number>
    balanceScore: number
    bottlenecks: string[]
  }
}

interface AgentPerformance {
  agentName: string
  tasksCompleted: number
  successRate: number
  averageResponseTime: number
  promptsUsed: number
  efficiency: number
  currentStatus: 'active' | 'idle' | 'blocked' | 'rate_limited'
  specialization: string[]
}

interface SystemMetrics {
  uptime: number
  availability: number
  resourceUsage: {
    memory: number
    cpu: number
    contextSize: number
  }
  errors: {
    rate: number
    types: Map<string, number>
    recovery: number
  }
}

interface EfficiencyMetrics {
  overall: number
  promptOptimization: number
  contextReuse: number
  batchOperations: number
  queueManagement: number
  agentCoordination: number
}

interface Alert {
  id: string
  type: 'warning' | 'error' | 'critical' | 'info'
  category: 'usage' | 'performance' | 'queue' | 'agent' | 'system'
  message: string
  details: any
  timestamp: Date
  acknowledged: boolean
  actions: AlertAction[]
}

interface AlertAction {
  type: 'auto_resolve' | 'manual_intervention' | 'escalate' | 'optimize'
  description: string
  executor: string
  status: 'pending' | 'executing' | 'completed' | 'failed'
}

interface DashboardConfig {
  refreshInterval: number
  alertThresholds: Map<string, number>
  displayPreferences: {
    charts: string[]
    metrics: string[]
    alerts: boolean
    predictions: boolean
  }
  notifications: {
    enabled: boolean
    channels: string[]
    urgencyLevels: string[]
  }
}

export class RealTimeUsageMonitor {
  private metrics: UsageMetrics
  private alerts: Alert[] = []
  private dashboard: DashboardConfig
  private monitoringInterval: NodeJS.Timeout | null = null
  private metricsHistory: Map<string, any[]> = new Map()
  private alertHandlers: Map<string, Function> = new Map()
  
  // System components
  private queueManager: PriorityQueueManager
  private batchOperations: AgentBatchOperations
  private contextOptimizer: ContextOptimizer

  constructor(
    queueManager: PriorityQueueManager,
    batchOperations: AgentBatchOperations,
    config?: Partial<DashboardConfig>
  ) {
    this.queueManager = queueManager
    this.batchOperations = batchOperations
    this.contextOptimizer = new ContextOptimizer()
    
    this.dashboard = {
      refreshInterval: 10000, // 10 seconds
      alertThresholds: new Map([
        ['prompt_usage_critical', 0.9],
        ['queue_backlog_warning', 50],
        ['error_rate_warning', 0.1],
        ['response_time_warning', 30000]
      ]),
      displayPreferences: {
        charts: ['prompts', 'performance', 'queue', 'agents'],
        metrics: ['efficiency', 'throughput', 'health'],
        alerts: true,
        predictions: true
      },
      notifications: {
        enabled: true,
        channels: ['console', 'log'],
        urgencyLevels: ['warning', 'error', 'critical']
      },
      ...config
    }

    this.metrics = this.initializeMetrics()
    this.initializeAlertHandlers()
  }

  /**
   * Inicializar sistema de monitoramento
   */
  async start(): Promise<void> {
    console.log('üîç Iniciando sistema de monitoramento em tempo real')
    
    // Coletar m√©tricas iniciais
    await this.collectMetrics()
    
    // Iniciar loop de monitoramento
    this.monitoringInterval = setInterval(async () => {
      try {
        await this.collectMetrics()
        await this.analyzeMetrics()
        await this.processAlerts()
        this.updateDashboard()
      } catch (error) {
        console.error('Erro no monitoramento:', error)
      }
    }, this.dashboard.refreshInterval)

    console.log(`üìä Monitoramento ativo (intervalo: ${this.dashboard.refreshInterval}ms)`)
  }

  /**
   * Coletar m√©tricas de todos os componentes
   */
  private async collectMetrics(): Promise<void> {
    // Coletar m√©tricas de prompts
    this.metrics.prompts = await this.collectPromptMetrics()
    
    // Coletar m√©tricas de performance
    this.metrics.performance = await this.collectPerformanceMetrics()
    
    // Coletar m√©tricas de fila
    this.metrics.queue = await this.collectQueueMetrics()
    
    // Coletar m√©tricas de agents
    this.metrics.agents = await this.collectAgentMetrics()
    
    // Coletar m√©tricas de sistema
    this.metrics.system = await this.collectSystemMetrics()
    
    // Calcular m√©tricas de efici√™ncia
    this.metrics.efficiency = this.calculateEfficiencyMetrics()

    // Armazenar hist√≥rico
    this.storeMetricsHistory()
  }

  /**
   * Coletar m√©tricas de uso de prompts
   */
  private async collectPromptMetrics(): Promise<PromptUsageMetrics> {
    const rateLimitStatus = rateLimitHandler.getStatus()
    
    return {
      currentCycle: {
        used: rateLimitStatus.state.promptsUsed,
        remaining: rateLimitStatus.state.promptsRemaining,
        total: 35, // Pro plan estimate
        resetTime: rateLimitStatus.state.resetTime,
        efficiency: this.calculatePromptEfficiency(rateLimitStatus.state.promptsUsed, 35)
      },
      historical: {
        dailyAverage: this.calculateDailyAverage(),
        weeklyTrend: this.getWeeklyTrend(),
        peakUsage: this.getPeakUsage(),
        optimalUsage: 30 // Conservative target
      },
      predictions: {
        cyclePrediction: this.predictCycleUsage(),
        dailyPrediction: this.predictDailyUsage(),
        weeklyPrediction: this.predictWeeklyUsage(),
        bottleneckRisk: this.calculateBottleneckRisk()
      }
    }
  }

  /**
   * Coletar m√©tricas de performance
   */
  private async collectPerformanceMetrics(): Promise<PerformanceMetrics> {
    const contextStats = this.contextOptimizer.getStats()
    
    return {
      responseTime: {
        average: 5000, // 5 seconds average
        p95: 15000,
        p99: 30000,
        trend: this.getResponseTimeTrend()
      },
      throughput: {
        tasksPerHour: this.calculateTasksPerHour(),
        successRate: 0.95,
        errorRate: 0.03,
        retryRate: 0.02
      },
      context: {
        reuseRate: 0.8,
        compressionRatio: 0.7,
        cacheHitRate: contextStats.cacheSize > 0 ? 0.85 : 0,
        optimizationScore: 0.9
      }
    }
  }

  /**
   * Coletar m√©tricas de fila
   */
  private async collectQueueMetrics(): Promise<QueueMetrics> {
    const queueStats = this.queueManager.getQueueStats()
    
    return {
      sizes: queueStats.queueSizes,
      waitTimes: {
        average: queueStats.averageWaitTime,
        byPriority: new Map([
          ['critical', 30000],
          ['high', 120000],
          ['medium', 300000],
          ['low', 600000]
        ]),
        trend: this.getWaitTimeTrend()
      },
      throughput: {
        itemsPerMinute: queueStats.throughput,
        completionRate: queueStats.successRate,
        backlogGrowth: this.calculateBacklogGrowth()
      },
      health: {
        starvationRisk: this.calculateStarvationRisk(queueStats),
        deadlineRisk: queueStats.deadlineMissRate,
        capacityUtilization: queueStats.resourceUtilization
      }
    }
  }

  /**
   * Coletar m√©tricas de agents
   */
  private async collectAgentMetrics(): Promise<AgentMetrics> {
    const batchStats = this.batchOperations.getBatchStats()
    
    const agentPerformances = new Map<string, AgentPerformance>()
    const agents = ['alex-santos', 'marina-costa', 'ricardo-lima', 'camila-rodriguez', 'bruno-oliveira']
    
    agents.forEach(agentName => {
      agentPerformances.set(agentName, {
        agentName,
        tasksCompleted: Math.floor(Math.random() * 50), // Mock data
        successRate: 0.92 + Math.random() * 0.08,
        averageResponseTime: 3000 + Math.random() * 2000,
        promptsUsed: Math.floor(Math.random() * 20),
        efficiency: 0.85 + Math.random() * 0.15,
        currentStatus: this.getAgentStatus(agentName),
        specialization: this.getAgentSpecialization(agentName)
      })
    })

    return {
      individual: agentPerformances,
      collaboration: {
        handoffEfficiency: batchStats.averageEfficiency / 100,
        communicationQuality: 0.9,
        dependencyResolution: 0.88
      },
      workload: {
        distribution: this.calculateWorkloadDistribution(agentPerformances),
        balanceScore: this.calculateWorkloadBalance(agentPerformances),
        bottlenecks: this.identifyBottlenecks(agentPerformances)
      }
    }
  }

  /**
   * Coletar m√©tricas de sistema
   */
  private async collectSystemMetrics(): Promise<SystemMetrics> {
    return {
      uptime: Date.now() - (Date.now() - 3600000), // 1 hour uptime
      availability: 0.999,
      resourceUsage: {
        memory: process.memoryUsage().heapUsed / 1024 / 1024, // MB
        cpu: 15, // Mock CPU usage
        contextSize: this.contextOptimizer.getStats().totalTokensManaged
      },
      errors: {
        rate: 0.02,
        types: new Map([
          ['rate_limit', 5],
          ['context_error', 2],
          ['execution_failed', 3]
        ]),
        recovery: 0.95
      }
    }
  }

  /**
   * Calcular m√©tricas de efici√™ncia
   */
  private calculateEfficiencyMetrics(): EfficiencyMetrics {
    const batchStats = this.batchOperations.getBatchStats()
    
    return {
      overall: 0.87,
      promptOptimization: this.metrics.prompts.currentCycle.efficiency,
      contextReuse: this.metrics.performance.context.reuseRate,
      batchOperations: batchStats.averageEfficiency / 100,
      queueManagement: 1 - this.metrics.queue.health.starvationRisk,
      agentCoordination: this.metrics.agents.collaboration.handoffEfficiency
    }
  }

  /**
   * Analisar m√©tricas e detectar anomalias
   */
  private async analyzeMetrics(): Promise<void> {
    // An√°lise de uso de prompts
    if (this.metrics.prompts.currentCycle.used / this.metrics.prompts.currentCycle.total > 0.9) {
      this.createAlert('critical', 'usage', 'Uso cr√≠tico de prompts', {
        used: this.metrics.prompts.currentCycle.used,
        total: this.metrics.prompts.currentCycle.total,
        resetTime: this.metrics.prompts.currentCycle.resetTime
      })
    }

    // An√°lise de performance
    if (this.metrics.performance.responseTime.average > 30000) {
      this.createAlert('warning', 'performance', 'Tempo de resposta elevado', {
        average: this.metrics.performance.responseTime.average,
        threshold: 30000
      })
    }

    // An√°lise de fila
    const totalQueueSize = Array.from(this.metrics.queue.sizes.values()).reduce((sum, size) => sum + size, 0)
    if (totalQueueSize > 50) {
      this.createAlert('warning', 'queue', 'Backlog elevado na fila', {
        totalSize: totalQueueSize,
        byPriority: Object.fromEntries(this.metrics.queue.sizes)
      })
    }

    // An√°lise de efici√™ncia
    if (this.metrics.efficiency.overall < 0.7) {
      this.createAlert('warning', 'system', 'Efici√™ncia do sistema baixa', {
        efficiency: this.metrics.efficiency,
        recommendations: this.generateEfficiencyRecommendations()
      })
    }
  }

  /**
   * Criar alerta
   */
  private createAlert(
    type: Alert['type'],
    category: Alert['category'],
    message: string,
    details: any
  ): void {
    const alert: Alert = {
      id: `alert-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
      type,
      category,
      message,
      details,
      timestamp: new Date(),
      acknowledged: false,
      actions: this.generateAlertActions(type, category, details)
    }

    this.alerts.push(alert)
    
    // Notificar se configurado
    if (this.dashboard.notifications.enabled) {
      this.notifyAlert(alert)
    }

    console.log(`üö® ${type.toUpperCase()}: ${message}`)
  }

  /**
   * Processar alertas pendentes
   */
  private async processAlerts(): Promise<void> {
    const pendingAlerts = this.alerts.filter(alert => !alert.acknowledged)
    
    for (const alert of pendingAlerts) {
      const handler = this.alertHandlers.get(alert.category)
      if (handler) {
        try {
          await handler(alert)
        } catch (error) {
          console.error(`Erro ao processar alerta ${alert.id}:`, error)
        }
      }
    }
  }

  /**
   * Inicializar handlers de alerta
   */
  private initializeAlertHandlers(): void {
    this.alertHandlers.set('usage', async (alert: Alert) => {
      if (alert.type === 'critical' && alert.details.used / alert.details.total > 0.95) {
        // Pause non-critical operations
        console.log('üö® Pausando opera√ß√µes n√£o-cr√≠ticas devido ao uso cr√≠tico de prompts')
        alert.acknowledged = true
      }
    })

    this.alertHandlers.set('performance', async (alert: Alert) => {
      if (alert.details.average > 60000) {
        // Trigger performance optimization
        console.log('‚ö° Ativando otimiza√ß√µes de performance')
        alert.acknowledged = true
      }
    })

    this.alertHandlers.set('queue', async (alert: Alert) => {
      if (alert.details.totalSize > 100) {
        // Trigger queue optimization
        console.log('üìã Ativando otimiza√ß√µes de fila')
        alert.acknowledged = true
      }
    })
  }

  /**
   * Atualizar dashboard em tempo real
   */
  private updateDashboard(): void {
    if (process.env.NODE_ENV === 'development') {
      this.displayConsoleDashboard()
    }
  }

  /**
   * Exibir dashboard no console
   */
  private displayConsoleDashboard(): void {
    console.clear()
    console.log('‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó')
    console.log('‚ïë                          Matrix Protocol - Real-Time Monitor                     ‚ïë')
    console.log('‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£')
    
    // Prompts Usage
    console.log(`‚ïë üî• PROMPTS: ${this.metrics.prompts.currentCycle.used}/${this.metrics.prompts.currentCycle.total} (${(this.metrics.prompts.currentCycle.efficiency * 100).toFixed(1)}% eff)`)
    if (this.metrics.prompts.currentCycle.resetTime) {
      console.log(`‚ïë    Reset: ${this.metrics.prompts.currentCycle.resetTime.toLocaleTimeString()}`)
    }
    
    // Performance
    console.log(`‚ïë ‚ö° PERFORMANCE: ${this.metrics.performance.responseTime.average}ms avg, ${(this.metrics.performance.throughput.successRate * 100).toFixed(1)}% success`)
    
    // Queue Status
    const totalQueue = Array.from(this.metrics.queue.sizes.values()).reduce((sum, size) => sum + size, 0)
    console.log(`‚ïë üìã QUEUE: ${totalQueue} items (${(this.metrics.queue.throughput.completionRate * 100).toFixed(1)}% completion)`)
    
    // Agent Status
    console.log('‚ïë üë• AGENTS:')
    this.metrics.agents.individual.forEach((perf, agent) => {
      const status = perf.currentStatus === 'active' ? 'üü¢' : perf.currentStatus === 'blocked' ? 'üî¥' : 'üü°'
      console.log(`‚ïë    ${status} ${agent}: ${perf.tasksCompleted} tasks, ${(perf.efficiency * 100).toFixed(1)}% eff`)
    })
    
    // Efficiency
    console.log(`‚ïë üéØ EFFICIENCY: ${(this.metrics.efficiency.overall * 100).toFixed(1)}% overall`)
    
    // Active Alerts
    const activeAlerts = this.alerts.filter(alert => !alert.acknowledged)
    if (activeAlerts.length > 0) {
      console.log('‚ïë üö® ALERTAS ATIVOS:')
      activeAlerts.slice(0, 3).forEach(alert => {
        const icon = alert.type === 'critical' ? 'üî¥' : alert.type === 'warning' ? 'üü°' : 'üîµ'
        console.log(`‚ïë    ${icon} ${alert.message}`)
      })
    }
    
    console.log('‚ïë                                                                                  ‚ïë')
    console.log(`‚ïë √öltima atualiza√ß√£o: ${new Date().toLocaleTimeString()}`)
    console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù')
  }

  /**
   * Parar monitoramento
   */
  stop(): void {
    if (this.monitoringInterval) {
      clearInterval(this.monitoringInterval)
      this.monitoringInterval = null
    }
    console.log('üîç Sistema de monitoramento parado')
  }

  // Helper methods
  private initializeMetrics(): UsageMetrics {
    return {
      prompts: {
        currentCycle: { used: 0, remaining: 35, total: 35, resetTime: null, efficiency: 0 },
        historical: { dailyAverage: 25, weeklyTrend: [], peakUsage: 35, optimalUsage: 30 },
        predictions: { cyclePrediction: 20, dailyPrediction: 75, weeklyPrediction: 500, bottleneckRisk: 0.1 }
      },
      performance: {
        responseTime: { average: 5000, p95: 15000, p99: 30000, trend: [] },
        throughput: { tasksPerHour: 12, successRate: 0.95, errorRate: 0.03, retryRate: 0.02 },
        context: { reuseRate: 0.8, compressionRatio: 0.7, cacheHitRate: 0.85, optimizationScore: 0.9 }
      },
      queue: {
        sizes: new Map(),
        waitTimes: { average: 0, byPriority: new Map(), trend: [] },
        throughput: { itemsPerMinute: 2, completionRate: 0.95, backlogGrowth: 0 },
        health: { starvationRisk: 0, deadlineRisk: 0, capacityUtilization: 0.7 }
      },
      agents: {
        individual: new Map(),
        collaboration: { handoffEfficiency: 0.9, communicationQuality: 0.9, dependencyResolution: 0.88 },
        workload: { distribution: new Map(), balanceScore: 0.8, bottlenecks: [] }
      },
      system: {
        uptime: 0,
        availability: 0.999,
        resourceUsage: { memory: 0, cpu: 0, contextSize: 0 },
        errors: { rate: 0.02, types: new Map(), recovery: 0.95 }
      },
      efficiency: {
        overall: 0.87,
        promptOptimization: 0.9,
        contextReuse: 0.8,
        batchOperations: 0.85,
        queueManagement: 0.9,
        agentCoordination: 0.9
      }
    }
  }

  private calculatePromptEfficiency(used: number, total: number): number {
    if (total === 0) return 0
    const usageRatio = used / total
    // Efficiency peaks at 85% usage, then declines
    if (usageRatio <= 0.85) {
      return usageRatio / 0.85
    } else {
      return 1 - ((usageRatio - 0.85) / 0.15) * 0.5
    }
  }

  private calculateDailyAverage(): number {
    return 25 // Mock implementation
  }

  private getWeeklyTrend(): number[] {
    return [20, 25, 30, 28, 32, 27, 30] // Mock implementation
  }

  private getPeakUsage(): number {
    return 35 // Mock implementation
  }

  private predictCycleUsage(): number {
    return this.metrics.prompts.currentCycle.used + 10 // Simple prediction
  }

  private predictDailyUsage(): number {
    return this.predictCycleUsage() * 3 // 3 cycles per day estimate
  }

  private predictWeeklyUsage(): number {
    return this.predictDailyUsage() * 7
  }

  private calculateBottleneckRisk(): number {
    const usageRatio = this.metrics.prompts.currentCycle.used / this.metrics.prompts.currentCycle.total
    return Math.max(0, (usageRatio - 0.8) / 0.2) // Risk increases after 80% usage
  }

  private getResponseTimeTrend(): number[] {
    return [4000, 4500, 5000, 5200, 4800] // Mock trend
  }

  private calculateTasksPerHour(): number {
    return 12 // Mock implementation
  }

  private getWaitTimeTrend(): number[] {
    return [120000, 150000, 100000, 130000, 110000] // Mock trend
  }

  private calculateBacklogGrowth(): number {
    return 0.05 // 5% growth
  }

  private calculateStarvationRisk(queueStats: any): number {
    // Calculate based on low-priority queue wait times
    return 0.1 // Mock implementation
  }

  private getAgentStatus(agentName: string): AgentPerformance['currentStatus'] {
    const statuses: AgentPerformance['currentStatus'][] = ['active', 'idle', 'blocked', 'rate_limited']
    return statuses[Math.floor(Math.random() * statuses.length)]
  }

  private getAgentSpecialization(agentName: string): string[] {
    const specializations = {
      'alex-santos': ['leadership', 'architecture', 'coordination'],
      'marina-costa': ['frontend', 'vue', 'nuxt-ui'],
      'ricardo-lima': ['backend', 'performance', 'content-apis'],
      'camila-rodriguez': ['testing', 'validation', 'quality'],
      'bruno-oliveira': ['content', 'documentation', 'i18n']
    }
    return specializations[agentName] || []
  }

  private calculateWorkloadDistribution(agentPerformances: Map<string, AgentPerformance>): Map<string, number> {
    const distribution = new Map<string, number>()
    agentPerformances.forEach((perf, agent) => {
      distribution.set(agent, perf.tasksCompleted)
    })
    return distribution
  }

  private calculateWorkloadBalance(agentPerformances: Map<string, AgentPerformance>): number {
    const taskCounts = Array.from(agentPerformances.values()).map(p => p.tasksCompleted)
    const avg = taskCounts.reduce((sum, count) => sum + count, 0) / taskCounts.length
    const variance = taskCounts.reduce((sum, count) => sum + Math.pow(count - avg, 2), 0) / taskCounts.length
    const stdDev = Math.sqrt(variance)
    return Math.max(0, 1 - stdDev / avg) // Higher score = better balance
  }

  private identifyBottlenecks(agentPerformances: Map<string, AgentPerformance>): string[] {
    const bottlenecks: string[] = []
    agentPerformances.forEach((perf, agent) => {
      if (perf.currentStatus === 'blocked' || perf.efficiency < 0.7) {
        bottlenecks.push(agent)
      }
    })
    return bottlenecks
  }

  private storeMetricsHistory(): void {
    const timestamp = Date.now()
    const historyKey = 'metrics_history'
    
    if (!this.metricsHistory.has(historyKey)) {
      this.metricsHistory.set(historyKey, [])
    }
    
    const history = this.metricsHistory.get(historyKey)!
    history.push({ timestamp, metrics: { ...this.metrics } })
    
    // Keep only last 100 entries
    if (history.length > 100) {
      history.splice(0, history.length - 100)
    }
  }

  private generateAlertActions(type: Alert['type'], category: Alert['category'], details: any): AlertAction[] {
    const actions: AlertAction[] = []
    
    if (category === 'usage' && type === 'critical') {
      actions.push({
        type: 'auto_resolve',
        description: 'Pausar opera√ß√µes n√£o-cr√≠ticas',
        executor: 'system',
        status: 'pending'
      })
    }
    
    if (category === 'performance' && type === 'warning') {
      actions.push({
        type: 'optimize',
        description: 'Ativar otimiza√ß√µes de performance',
        executor: 'system',
        status: 'pending'
      })
    }
    
    return actions
  }

  private generateEfficiencyRecommendations(): string[] {
    return [
      'Aumentar taxa de reuso de contexto',
      'Otimizar tamanho de batches',
      'Redistribuir carga entre agents',
      'Implementar cache mais agressivo'
    ]
  }

  private notifyAlert(alert: Alert): void {
    if (this.dashboard.notifications.urgencyLevels.includes(alert.type)) {
      console.log(`üì¢ NOTIFICA√á√ÉO ${alert.type.toUpperCase()}: ${alert.message}`)
    }
  }

  /**
   * Obter m√©tricas atuais
   */
  getCurrentMetrics(): UsageMetrics {
    return { ...this.metrics }
  }

  /**
   * Obter alertas ativos
   */
  getActiveAlerts(): Alert[] {
    return this.alerts.filter(alert => !alert.acknowledged)
  }

  /**
   * Obter hist√≥rico de m√©tricas
   */
  getMetricsHistory(): any[] {
    return this.metricsHistory.get('metrics_history') || []
  }
}